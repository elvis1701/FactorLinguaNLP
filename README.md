# FactorLinguaNLP

FactorLinguaNLP √© um sistema completo de **tradu√ß√£o neural** (NMT) inspirado no Transformer, criado inicialmente com um √∫nico arquivo (`translingua.py`) e hoje expandido com **pipeline de dados** (`prepare_data.py`) e **interface gr√°fica** (`factorlingua_gui.py`). √â um projeto educacional e extens√≠vel, que demonstra como construir um tradutor neural de ponta a ponta ‚Äî da tokeniza√ß√£o ao uso via GUI.

---

## ‚ú® Principais destaques

* **Aten√ß√£o hier√°rquica**: une aten√ß√£o **local** (janela de contexto) e **global**, controladas por um *gate* trein√°vel.
* **Codifica√ß√£o posicional din√¢mica**: seno/cosseno com escala **aprendida pelo modelo**.
* **Embeddings fatorizados**: compress√£o de vocabul√°rio para reduzir par√¢metros e projetar em `d_model`.
* **Treinamento est√°vel**: label smoothing, grad clipping e seeds reprodut√≠veis.
* **Infer√™ncia robusta**: `greedy_decode` lida com entradas vazias, tokeniza√ß√µes curtas e tokens inv√°lidos.
* **API clara**: fun√ß√µes dedicadas para carregar modelo/configura√ß√£o e traduzir via Python ou GUI.
* **Ferramenta de prepara√ß√£o**: `prepare_data.py` cria os tokenizadores SentencePiece.
* **Interface gr√°fica (Tkinter)**: `factorlingua_gui.py` permite treinar e traduzir sem terminal.

---

## üìÇ Estrutura do projeto

### `translingua.py`

Cora√ß√£o do sistema:

* **Modelo**: `TranslinguaModel` (encoder-decoder Transformer customizado).
* **Componentes**: aten√ß√£o hier√°rquica, embeddings fatorizados, positional encoding din√¢mico.
* **Dataset**: `TranslationDataset` com BOS/EOS, truncamento e padding.
* **Treinamento**: `train_model(...)` salva pesos + config.
* **Infer√™ncia**: `greedy_decode(...)` e `load_model_for_inference(...)`.

### `prepare_data.py`

* Treina modelos **SentencePiece** para origem e destino.
* Gera `src.model`, `src.vocab`, `tgt.model`, `tgt.vocab`.
* Usa BPE com alta cobertura de caracteres.

### `factorlingua_gui.py`

Interface gr√°fica para:

* Selecionar arquivos de treino.
* Iniciar treinamento com barra de log.
* Carregar modelo salvo.
* Traduzir textos digitados.
* Visualizar tokens de entrada (debug).
* Receber feedback visual com √≠cones (‚úÖ/‚ùå/üìÇ/üöÄ/üåê).

---

## üß† Pipeline completo

1. **Prepara√ß√£o de dados**

   * Rodar `prepare_data.py` com `frases_src.txt` e `frases_tgt.txt`.
   * Sa√≠da: `src.model` e `tgt.model`.

2. **Treinamento**

   * Executar `train_model(...)` com `train.src` e `train.tgt`.
   * Sa√≠da: `translingua.pt` (pesos) e `translingua_config.pt` (configura√ß√£o).

3. **Infer√™ncia**

   * Carregar com `load_model_for_inference(...)`.
   * Traduzir com `greedy_decode(...)`.

4. **Interface Gr√°fica**

   * Usar `factorlingua_gui.py` para treinar e traduzir sem precisar do terminal.

---

## üî© Fluxo em diagrama

```mermaid
flowchart LR
    A[Corpus paralelo] --> B[prepare_data.py]
    B --> C[src.model / tgt.model]
    C --> D[train_model em translingua.py]
    D --> E[translingua.pt + translingua_config.pt]
    E --> F[load_model_for_inference]

    subgraph GUI
    G[FactorLinguaGUI]
    G --> H[Carregar arquivos]
    G --> I[Treinar modelo]
    G --> J[Traduzir texto]
    end

    F --> J
    H --> I
```

---

## üöÄ Como usar

### 1. Preparar tokenizadores

```bash
python prepare_data.py
```

> Gera `src.model`, `tgt.model`, `src.vocab`, `tgt.vocab`.

### 2. Treinar modelo

```bash
python translingua.py
```

Ou programaticamente:

```python
from translingua import train_model

model = train_model(
    src_model_path="src.model",
    tgt_model_path="tgt.model",
    src_file="train.src",
    tgt_file="train.tgt",
    epochs=5,
)
```

### 3. Traduzir frases

```python
from translingua import load_model_for_inference, greedy_decode

model, src_sp, tgt_sp = load_model_for_inference(
    model_path="translingua.pt",
    config_path="translingua_config.pt",
    src_spm_path="src.model",
    tgt_spm_path="tgt.model",
)

print(greedy_decode(model, src_sp, tgt_sp, "hello world"))
```

### 4. Usar a interface gr√°fica

```bash
python factorlingua_gui.py
```

Interface abre com bot√µes para carregar dados, treinar e traduzir.

---

## üìà Avalia√ß√£o

* **Loss/token**: exibido durante o treino.
* **BLEU** e **chrF** recomendados via sacrebleu.
* **Curvas de treino** podem ser plotadas com matplotlib.

---

## üõ†Ô∏è Requisitos

### Requisitos m√≠nimos e recomendados

| Categoria     | M√≠nimo                             | Recomendado                          |
| ------------- | ---------------------------------- | ------------------------------------ |
| CPU           | Intel i5 4¬™ gera√ß√£o ou equivalente | Intel i7/i9 ou AMD Ryzen 7+          |
| GPU           | NVIDIA GTX 1050 Ti (4GB VRAM)      | NVIDIA RTX 3060 (12GB VRAM) ou acima |
| RAM           | 8 GB                               | 16 GB ou mais                        |
| Armazenamento | 5 GB livres                        | SSD NVMe 20 GB+                      |
| SO            | Windows 10 / Linux Ubuntu 20.04+   | Linux Ubuntu 22.04 / Windows 11 Pro  |

### Advert√™ncias de uso

* **Treinamento em GPU**: pode gerar aquecimento intenso. Certifique-se de ter refrigera√ß√£o adequada.
* **GPUs de entrada (ex.: 1050 Ti)**: podem sofrer lentid√£o em datasets grandes. Prefira **batches pequenos**.
* **Uso em CPU**: poss√≠vel, mas extremamente mais lento.
* **Longos per√≠odos de treino**: podem causar desgaste de componentes, especialmente em hardware antigo.
* **Recomenda√ß√£o**: monitore temperatura e consumo el√©trico durante treinos longos.

---

## üíª IDEs recomendadas

| IDE        | Vantagens principais                                                       |
| ---------- | -------------------------------------------------------------------------- |
| VS Code    | Leve, excelente suporte a Python, Jupyter, Git e plugins de produtividade. |
| PyCharm    | Refatora√ß√£o avan√ßada, inspe√ß√µes est√°ticas, ideal para projetos maiores.    |
| JupyterLab | Experimentos r√°pidos, √≥tima integra√ß√£o com visualiza√ß√µes.                  |
| Spyder     | Ambiente cient√≠fico com integra√ß√£o forte em an√°lise de dados.              |

---

## üìö Poss√≠veis Cases para uso dessa ferramenta

* Tradu√ß√£o geral e de dom√≠nios espec√≠ficos (jur√≠dico, m√©dico, etc.).
* Legendas curtas (benef√≠cio do contexto local).
* Educa√ß√£o/pesquisa: comparar efeitos da aten√ß√£o local vs global.
* Aplica√ß√µes embarcadas: embeddings fatorizados reduzem mem√≥ria.

---

## üìä Exemplos de tradu√ß√£o

```text
EN: "He is reading a book."  
PT: "Ele est√° lendo um livro."

ES: "Hola mundo."  
EN: "Hello world."
```

> Resultados reais podem variar conforme os dados de treino e tempo de treinamento.

---

## üß™ Benchmarking inicial

* Treino r√°pido em \~1k pares de frases resulta em tradu√ß√µes b√°sicas compreens√≠veis.
* Para corpora maiores (50k+ frases), espera-se BLEU entre 15‚Äì25 (dependendo do dom√≠nio).
* Recomenda-se avalia√ß√£o com **sacrebleu** para padroniza√ß√£o.

---

## üõ£Ô∏è Roadmap de evolu√ß√£o

* [ ] Implementar beam search com length penalty.
* [ ] Suporte a m√∫ltiplos pares de idiomas.
* [ ] Exporta√ß√£o para ONNX para infer√™ncia r√°pida.
* [ ] Treinamento distribu√≠do multi-GPU.
* [ ] Fine-tuning em dom√≠nios espec√≠ficos (jur√≠dico, t√©cnico, sa√∫de).

---

## üåê Contribui√ß√µes

* Issues e sugest√µes s√£o bem-vindas no reposit√≥rio.
* Pull requests podem incluir:

  * Novos scripts de pr√©-processamento.
  * Melhorias na interface gr√°fica.
  * Novos m√©todos de infer√™ncia (ex.: beam search).

---

## üìÑ Licen√ßa

### English (Original)

MIT License

Copyright (c) 2025 Elvis Alves

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

### Portugu√™s (Tradu√ß√£o)

Licen√ßa MIT

Copyright (c) 2025 Elvis Alves

√â concedida permiss√£o, gratuitamente, a qualquer pessoa que obtenha uma c√≥pia
deste software e dos arquivos de documenta√ß√£o associados (o "Software"), para
negociar o Software sem restri√ß√£o, incluindo, sem limita√ß√£o, os direitos de
usar, copiar, modificar, mesclar, publicar, distribuir, sublicenciar e/ou vender
c√≥pias do Software, e permitir que as pessoas a quem o Software √© fornecido o
fa√ßam, sujeito √†s seguintes condi√ß√µes:

O aviso de copyright acima e este aviso de permiss√£o devem ser inclu√≠dos em
todas as c√≥pias ou partes substanciais do Software.

O SOFTWARE √â FORNECIDO "NO ESTADO EM QUE SE ENCONTRA", SEM GARANTIA DE QUALQUER
TIPO, EXPRESSA OU IMPL√çCITA, INCLUINDO, MAS N√ÉO SE LIMITANDO √ÄS GARANTIAS DE
COMERCIALIZA√á√ÉO, ADEQUA√á√ÉO A UM DETERMINADO FIM E N√ÉO INFRA√á√ÉO. EM NENHUM CASO
OS AUTORES OU DETENTORES DOS DIREITOS AUTORAIS SER√ÉO RESPONS√ÅVEIS POR QUALQUER
RECLAMA√á√ÉO, DANOS OU OUTRA RESPONSABILIDADE, SEJA EM UMA A√á√ÉO DE CONTRATO, IL√çCITO
OU DE OUTRA FORMA, DECORRENTE DE, FORA OU EM CONEX√ÉO COM O SOFTWARE OU O USO OU
OUTRAS NEGOCIA√á√ïES NO SOFTWARE.

---

### ‚úÖ Resumo final

* `translingua.py` ‚Üí n√∫cleo Transformer + treino + infer√™ncia.
* `prepare_data.py` ‚Üí tokenizadores SentencePiece.
* `factorlingua_gui.py` ‚Üí interface gr√°fica.

üëâ O **FactorLinguaNLP** evoluiu de um √∫nico script para um **ecossistema completo de tradu√ß√£o neural**, cobrindo todo o ciclo: **pr√©-processamento ‚Üí treino ‚Üí infer√™ncia ‚Üí interface gr√°fica**.
